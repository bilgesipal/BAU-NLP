{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Stemming using NLTK\n",
    "Stemming is the process of reducing a word to its root without considering context. It often produces words that are not real dictionary words."
   ],
   "id": "a2fd96c39c41b5e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install nltk",
   "id": "5d896a1d2b3b6de3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# initialize the PorterStemmer Class\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = [\"running\", \"studies\", \"flying\", \"better\", \"geese\", \"children\"]\n",
    "stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "#print the results\n",
    "print(stemmed_words)\n"
   ],
   "id": "f2bca46dce17a50f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Lemmatization\n",
    "Lemmatization is the process of reducing a word to its base or dictionary form (lemma) while considering its context and meaning. Unlike stemming, lemmatization produces real words."
   ],
   "id": "cc4ab953d9bcf291"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lemmatization with NLTK",
   "id": "a3da2bda86fa497c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')  # Ensure you have WordNet data\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Example words\n",
    "words = [\"running\", \"flies\", \"better\", \"geese\", \"mice\", \"studies\", \"children\", \"was\", \"went\"]\n",
    "\n",
    "# Lemmatizing words\n",
    "lemmatized_words = [lemmatizer.lemmatize(word, wordnet.VERB) for word in words]\n",
    "\n",
    "print(lemmatized_words)\n"
   ],
   "id": "ef98289b30c4680e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Lemmatization with Spacy",
   "id": "61c19db542a51480"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!pip install spacy",
   "id": "5cc68f4793e08b73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "#spacy.cli.download(\"en_core_web_sm\")"
   ],
   "id": "15da9a71ba55eb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#Smaller Model\n",
    "nlp_sm = spacy.load(\"en_core_web_sm\")\n",
    "# Large Model\n",
    "nlp_lg = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "text = \"The children were running faster than the mice, but the geese had already flown.\"\n",
    "\n",
    "doc_sm = nlp_sm(text)\n",
    "doc_lg = nlp_lg(text)\n",
    "\n",
    "# Lemmatized words\n",
    "lemmatized_text_sm = \" \".join([token.lemma_ for token in doc_sm])\n",
    "lemmatized_text_lg = \" \".join([token.lemma_ for token in doc_lg])\n",
    "\n",
    "print('Result of the small model:', lemmatized_text_sm)\n",
    "\n",
    "print('Result of the large model:', lemmatized_text_lg)"
   ],
   "id": "e3ed6954fb076a37",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
